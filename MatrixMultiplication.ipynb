{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicação de 2 matrices quadradas utilizando um bloco unico de therads e uma memoria global. Cada thread calcula um elemento do resultado da matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycuda import compiler, gpuarray, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inicializar o device\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos nossa função de Kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_code = \"\"\"\n",
    "__global__ void MatrixMulKernel(float *a, float *b, float *c, int matrixSize)\n",
    "{\n",
    "    // Thread 2D \n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    \n",
    "    // Criamos Pvalue para armazenar os elementos da matrix que estão sendo computadas\n",
    "    float Pvalue = 0;\n",
    "    \n",
    "    // Each thread loads one row of M and one column of N,\n",
    "    // to produce one element of P.\n",
    "    for (int k=0; k< matrixSize; ++k) {\n",
    "        float Aelement = a[ty * matrixSize + k];\n",
    "        float Belement = b[k * matrixSize + tx];\n",
    "        Pvalue += Aelement*Belement;\n",
    "    }\n",
    "\n",
    "    //Escreve a matriz na memoria do GPU\n",
    "    //Cada thread escreve um elemento\n",
    "    c[ty * matrixSize + tx] = Pvalue;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos as variáveis no CPU , criamos 2 matrizes quadradas aleatorias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MATRIX_SIZE=2\n",
    "\n",
    "a_cpu = np.random.randn(MATRIX_SIZE,MATRIX_SIZE).astype(np.float32)\n",
    "b_cpu = np.random.randn(MATRIX_SIZE,MATRIX_SIZE).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculamos nossa referencia multiplicando a_cpu*b_cpu para comparar com o calculo em GPU\n",
    "c_cpu = np.dot(a_cpu,b_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos as variáveis no GPU , transferir da memoria do host (CPU) para memoria do device (GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_gpu = gpuarray.to_gpu(a_cpu)\n",
    "b_gpu = gpuarray.to_gpu(b_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criamos uma matriz vazia para o resultado (C = A * B)\n",
    "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos o kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpuuser/miniconda2/envs/envanaconda33/lib/python3.3/site-packages/ipykernel/__main__.py:1: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "mod = compiler.SourceModule(kernel_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegamos a função do kernel desde o modulo compilado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrixmul = mod.get_function(\"MatrixMulKernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamamos o kernel que está no GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrixmul(\n",
    "        # inputs\n",
    "        a_gpu, b_gpu,\n",
    "        # output\n",
    "        c_gpu,\n",
    "        # matrix_size\n",
    "        np.int32(MATRIX_SIZE),\n",
    "        # (só um bloco) um bloco de dimensão MATRIX_SIZE x MATRIX_SIZE threads\n",
    "        block = (MATRIX_SIZE, MATRIX_SIZE,1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresentamos os resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Matrix A (GPU):\n",
      "[[-0.01832112 -0.62257814]\n",
      " [ 2.017344   -1.30206716]]\n",
      "--------------------------------------------------------------------------------\n",
      "Matrix B (GPU):\n",
      "[[-0.05257856 -0.95913631]\n",
      " [ 1.8141917  -1.26291764]]\n",
      "--------------------------------------------------------------------------------\n",
      "Matrix C (GPU):\n",
      "[[-1.12851286  0.80383736]\n",
      " [-2.46826839 -0.29050434]]\n",
      "--------------------------------------------------------------------------------\n",
      "CPU-GPU difference:\n",
      "[[  1.19209290e-07   0.00000000e+00]\n",
      " [ -2.38418579e-07   0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-\" * 80)\n",
    "print(\"Matrix A (GPU):\")\n",
    "print(a_gpu.get())\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"Matrix B (GPU):\")\n",
    "print(b_gpu.get())\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"Matrix C (GPU):\")\n",
    "print(c_gpu.get())\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"CPU-GPU difference:\")\n",
    "print(c_cpu - c_gpu.get())\n",
    "\n",
    "np.allclose(c_cpu, c_gpu.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
